# Complexidade Logar√≠tmica

# Agora, vamos entender o que √© a Complexidade Logar√≠tmica. Mas, antes disso, √© preciso deixar n√≠tido que, apesar do termo potencialmente assustador, a Complexidade Logar√≠tmica n√£o exige c√°lculos matem√°ticos complicados para ser entendida. üôÇ

# Representado pela nota√ß√£o O(log n), um algoritmo logar√≠tmico tem uma altera√ß√£o na taxa de execu√ß√£o que, geralmente, reduz pela metade o tempo de finaliza√ß√£o das itera√ß√µes ao reduzir pela metade o tamanho do input a cada itera√ß√£o.

# Vamos refletir sobre isso:

##### Suponha que temos um algoritmo cuja entrada n √© igual a 4, se tivermos um algoritmo O(log n) a ser executado com essa entrada, teremos que fazer apenas 2 opera√ß√µes para execut√°-lo, pois log‚ÇÇn (l√™-se: "log de n na base 2") √© igual a 2. Se a nossa entrada fosse o dobro, ou seja, 8 ter√≠amos que realizar apenas 3 opera√ß√µes para chegar ao fim da execu√ß√£o. Ao dobrar o valor da entrada novamente, com n igual a 16, ter√≠amos que realizar apenas 4 opera√ß√µes (log‚ÇÇn √© igual a 4) e assim sucessivamente. #####


# Anota a√≠ üñä: O n√∫mero de opera√ß√µes para executar o algoritmo logar√≠tmico tem uma rela√ß√£o inversa ao tamanho da entrada: quanto maior ela √©, menor o n√∫mero de opera√ß√µes e, consequentemente, menor o tempo para a execu√ß√£o do algoritmo!
